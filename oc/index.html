<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Optical Camouflage</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&display=swap" rel="stylesheet">
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    
    :root {
      --bg: #0a0a0a;
      --surface: #141414;
      --border: #222;
      --text: #fff;
      --text-muted: #666;
      --accent: #fff;
    }
    
    html, body { 
      background: var(--bg);
      color: var(--text); 
      font-family: 'Space Grotesk', system-ui, sans-serif;
      min-height: 100vh;
      -webkit-font-smoothing: antialiased;
    }
    
    .app { 
      display: flex;
      flex-direction: column;
      height: 100vh;
    }
    
    /* Header */
    header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 20px 32px;
      border-bottom: 1px solid var(--border);
    }
    
    .logo {
      font-size: 14px;
      font-weight: 600;
      letter-spacing: 0.5px;
    }
    
    .version {
      font-size: 11px;
      color: var(--text-muted);
      margin-left: 8px;
    }
    
    /* Controls */
    .controls {
      display: flex;
      align-items: center;
      gap: 8px;
      padding: 16px 32px;
      border-bottom: 1px solid var(--border);
      flex-wrap: wrap;
    }
    
    .btn {
      font-family: inherit;
      font-size: 13px;
      font-weight: 500;
      padding: 10px 18px;
      border: 1px solid var(--border);
      border-radius: 8px;
      background: transparent;
      color: var(--text);
      cursor: pointer;
      transition: all 0.15s ease;
    }
    
    .btn:hover {
      background: var(--surface);
      border-color: #333;
    }
    
    .btn:disabled {
      opacity: 0.3;
      cursor: not-allowed;
    }
    
    .btn-primary {
      background: var(--text);
      color: var(--bg);
      border-color: var(--text);
    }
    
    .btn-primary:hover {
      opacity: 0.9;
      background: var(--text);
    }
    
    .divider {
      width: 1px;
      height: 24px;
      background: var(--border);
      margin: 0 8px;
    }
    
    /* Slider */
    .slider {
      display: flex;
      align-items: center;
      gap: 12px;
    }
    
    .slider-label {
      font-size: 12px;
      color: var(--text-muted);
      min-width: 40px;
    }
    
    input[type="range"] {
      -webkit-appearance: none;
      width: 80px;
      height: 4px;
      background: var(--border);
      border-radius: 2px;
      outline: none;
    }
    
    input[type="range"]::-webkit-slider-thumb {
      -webkit-appearance: none;
      width: 14px;
      height: 14px;
      background: var(--text);
      border-radius: 50%;
      cursor: pointer;
      transition: transform 0.1s;
    }
    
    input[type="range"]::-webkit-slider-thumb:hover {
      transform: scale(1.15);
    }
    
    .slider-value {
      font-size: 12px;
      font-weight: 500;
      color: var(--text-muted);
      min-width: 32px;
      font-variant-numeric: tabular-nums;
    }
    
    /* Stage */
    .stage { 
      flex: 1;
      display: grid; 
      place-items: center;
      padding: 24px;
      background: var(--bg);
    }
    
    canvas { 
      max-width: 100%;
      max-height: 100%;
      border-radius: 12px;
      box-shadow: 0 0 0 1px var(--border);
    }
    
    video { display: none; }
    
    /* Status */
    .status { 
      position: fixed; 
      bottom: 24px;
      left: 50%;
      transform: translateX(-50%);
      background: var(--surface);
      padding: 12px 24px; 
      border-radius: 100px; 
      font-size: 13px;
      font-weight: 500;
      z-index: 100;
      border: 1px solid var(--border);
      display: flex;
      align-items: center;
      gap: 10px;
      transition: all 0.2s ease;
    }
    
    .status.active { 
      background: var(--text);
      color: var(--bg);
      border-color: var(--text);
    }
    
    .status-dot {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      background: var(--text-muted);
    }
    
    .status.active .status-dot {
      background: var(--bg);
      animation: blink 1s infinite;
    }
    
    @keyframes blink {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.3; }
    }
    
    /* Countdown */
    .countdown {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      font-size: 200px;
      font-weight: 700;
      color: var(--text);
      z-index: 200;
      pointer-events: none;
      opacity: 0.9;
    }
    
    /* Auto Status */
    .auto-status {
      position: fixed;
      top: 24px;
      left: 50%;
      transform: translateX(-50%);
      background: var(--surface);
      padding: 12px 20px;
      border-radius: 100px;
      font-size: 12px;
      font-weight: 500;
      z-index: 100;
      border: 1px solid var(--border);
      display: flex;
      align-items: center;
      gap: 8px;
    }
    
    .spinner {
      width: 14px;
      height: 14px;
      border: 2px solid var(--border);
      border-top-color: var(--text);
      border-radius: 50%;
      animation: spin 0.8s linear infinite;
    }
    
    @keyframes spin {
      to { transform: rotate(360deg); }
    }
    
    .auto-status.ready { 
      background: var(--text);
      color: var(--bg);
    }
    
    .auto-status.ready .spinner {
      display: none;
    }
    
    .auto-status.ready::before {
      content: '?';
      font-weight: 600;
    }
    
    /* Mobile */
    @media (max-width: 640px) {
      header { padding: 16px 20px; }
      .controls { padding: 12px 20px; gap: 6px; }
      .btn { padding: 8px 12px; font-size: 12px; }
      .slider { gap: 8px; }
      input[type="range"] { width: 60px; }
      .divider { display: none; }
      .countdown { font-size: 120px; }
    }
  </style>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
</head>

<body>
  <div class="app">
    <header>
      <div>
        <span class="logo">Optical Camouflage</span>
        <span class="version">v1.0</span>
      </div>
    </header>
    
    <div class="controls">
      <button id="btnStart" class="btn btn-primary">Start</button>
      <button id="btnAutoStart" class="btn">Auto</button>
      
      <span class="divider"></span>
      
      <button id="btnFreeze" class="btn" disabled>Freeze</button>
      <button id="btnUnfreeze" class="btn" disabled>Unfreeze</button>
      
      <span class="divider"></span>

      <div class="slider">
        <span class="slider-label">Cloak</span>
        <input id="mix" type="range" min="0" max="1" step="0.01" value="0.98" />
        <span id="mixVal" class="slider-value">0.98</span>
      </div>

      <div class="slider">
        <span class="slider-label">Edge</span>
        <input id="edge" type="range" min="0" max="10" step="0.1" value="3.0" />
        <span id="edgeVal" class="slider-value">3.0</span>
      </div>

      <div class="slider">
        <span class="slider-label">Warp</span>
        <input id="warp" type="range" min="0" max="12" step="0.1" value="4.0" />
        <span id="warpVal" class="slider-value">4.0</span>
      </div>
      
      <span class="divider"></span>

      <button id="btnGesture" class="btn" disabled>Gesture ?</button>
    </div>

    <div id="status" class="status" style="display:none;">
      <span class="status-dot"></span>
      <span id="statusText">Cloak OFF</span>
    </div>

    <div id="countdown" class="countdown" style="display:none;"></div>
    
    <div id="autoStatus" class="auto-status" style="display:none;">
      <span class="spinner"></span>
      <span id="autoStatusText">Detecting background...</span>
    </div>

    <div class="stage">
      <video id="video" playsinline></video>
      <canvas id="gl"></canvas>
    </div>
  </div>

<script>
(async () => {
  const video = document.getElementById('video');
  const canvas = document.getElementById('gl');
  const btnStart = document.getElementById('btnStart');
  const btnAutoStart = document.getElementById('btnAutoStart');
  const btnFreeze = document.getElementById('btnFreeze');
  const btnUnfreeze = document.getElementById('btnUnfreeze');
  const countdownEl = document.getElementById('countdown');
  const autoStatusEl = document.getElementById('autoStatus');
  const autoStatusText = document.getElementById('autoStatusText');

  const mixEl = document.getElementById('mix');
  const edgeEl = document.getElementById('edge');
  const warpEl = document.getElementById('warp');
  const mixVal = document.getElementById('mixVal');
  const edgeVal = document.getElementById('edgeVal');
  const warpVal = document.getElementById('warpVal');

  function syncUI() {
    mixVal.textContent = (+mixEl.value).toFixed(2);
    edgeVal.textContent = (+edgeEl.value).toFixed(1);
    warpVal.textContent = (+warpEl.value).toFixed(1);
  }
  [mixEl, edgeEl, warpEl].forEach(el => el.addEventListener('input', syncUI));
  syncUI();

  // ---------- WebGL2 setup ----------
  const gl = canvas.getContext('webgl2', { premultipliedAlpha:false, antialias:false });
  if (!gl) {
    alert('WebGL2 is not supported in this browser.');
    return;
  }

  const vsSrc = `#version 300 es
  precision highp float;
  in vec2 a_pos;
  out vec2 v_uv;
  void main() {
    // Flip Y and mirror X for correct camera orientation
    vec2 uv = (a_pos + 1.0) * 0.5;
    v_uv = vec2(1.0 - uv.x, 1.0 - uv.y);
    gl_Position = vec4(a_pos, 0.0, 1.0);
  }`;

  // 人物領域(=mask)にだけ多段合成した「背景っぽいもの」を描く
  // maskはMediaPipeのsegmentationMask（人物=1に近い）
  const fsSrc = `#version 300 es
  precision highp float;
  in vec2 v_uv;
  out vec4 outColor;

  uniform sampler2D u_now;     // current frame
  uniform sampler2D u_p1;      // past 1
  uniform sampler2D u_p2;      // past 2
  uniform sampler2D u_p3;      // past 3
  uniform sampler2D u_mask;    // segmentation mask (person ~1)
  uniform sampler2D u_freeze;  // frozen background (optional)

  uniform vec2  u_texel;       // 1/width, 1/height
  uniform float u_mix;         // cloak strength
  uniform float u_edge;        // edge blur
  uniform float u_warp;        // distortion strength
  uniform float u_useFreeze;   // 1 when frozen

  // cheap blur on mask to soften edges
  float blurMask(vec2 uv, float r) {
    // 9-tap box-ish blur (fast & simple)
    float s = 0.0;
    float w = 0.0;
    for (int y=-1; y<=1; y++) {
      for (int x=-1; x<=1; x++) {
        vec2 o = vec2(float(x), float(y)) * u_texel * r;
        float m = texture(u_mask, uv + o).r;
        s += m;
        w += 1.0;
      }
    }
    return s / w;
  }

  vec3 sampleWarped(sampler2D tex, vec2 uv, float t, float amp) {
    // subtle wave distortion
    float wx = sin((uv.y * 12.0 + t*1.7)) * amp;
    float wy = cos((uv.x * 10.0 - t*1.3)) * amp;
    vec2 duv = uv + vec2(wx, wy) * u_texel;
    return texture(tex, duv).rgb;
  }

  void main() {
    float t = float(gl_FragCoord.x + gl_FragCoord.y) * 0.0; // deterministic base
    vec3 now = texture(u_now, v_uv).rgb;

    // edge soften + slight dilate by boosting radius
    float m = blurMask(v_uv, max(0.0, u_edge));
    // Make mask sharper for better invisibility
    m = smoothstep(0.20, 0.55, m);
    // Boost mask strength
    m = pow(m, 0.7);

    // Multi-layer "cloak" from frozen bg + past frames
    // Layer offsets create "multi-stage" diagonal feel
    float amp = u_warp * 0.35;

    vec2 o1 = vec2( 1.5, -1.0) * u_texel * (2.0 + u_warp);
    vec2 o2 = vec2(-2.0,  1.2) * u_texel * (3.0 + u_warp);
    vec2 o3 = vec2( 2.2,  2.0) * u_texel * (4.0 + u_warp);

    // choose background source
    vec3 cloak;
    
    if (u_useFreeze > 0.5) {
      // When frozen: use frozen background directly (full replacement)
      cloak = texture(u_freeze, v_uv).rgb;
    } else {
      // No freeze: use past frames (less effective but still works)
      vec3 p1 = sampleWarped(u_p1, v_uv + o1, 1.0, amp);
      vec3 p2 = sampleWarped(u_p2, v_uv + o2, 2.0, amp * 1.2);
      vec3 p3 = sampleWarped(u_p3, v_uv + o3, 3.0, amp * 1.4);
      cloak = p1 * 0.5 + p2 * 0.3 + p3 * 0.2;
    }

    // subtle edge highlight (refraction effect at cloak boundary)
    float edge = smoothstep(0.20, 0.45, m) - smoothstep(0.55, 0.80, m);
    cloak += vec3(edge * 0.05);

    // apply cloak only on person area
    float k = clamp(u_mix, 0.0, 1.0);
    vec3 outRgb = mix(now, cloak, m * k);

    outColor = vec4(outRgb, 1.0);
  }`;

  function compile(type, src) {
    const s = gl.createShader(type);
    gl.shaderSource(s, src);
    gl.compileShader(s);
    if (!gl.getShaderParameter(s, gl.COMPILE_STATUS)) {
      console.error(gl.getShaderInfoLog(s));
      throw new Error('Shader compile failed');
    }
    return s;
  }
  function link(vs, fs) {
    const p = gl.createProgram();
    gl.attachShader(p, vs);
    gl.attachShader(p, fs);
    gl.linkProgram(p);
    if (!gl.getProgramParameter(p, gl.LINK_STATUS)) {
      console.error(gl.getProgramInfoLog(p));
      throw new Error('Program link failed');
    }
    return p;
  }

  const prog = link(compile(gl.VERTEX_SHADER, vsSrc), compile(gl.FRAGMENT_SHADER, fsSrc));
  gl.useProgram(prog);

  // Fullscreen quad
  const quad = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, quad);
  gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
    -1, -1,  1, -1, -1,  1,
    -1,  1,  1, -1,  1,  1
  ]), gl.STATIC_DRAW);

  const aPos = gl.getAttribLocation(prog, 'a_pos');
  gl.enableVertexAttribArray(aPos);
  gl.vertexAttribPointer(aPos, 2, gl.FLOAT, false, 0, 0);

  // uniforms
  const U = {
    now: gl.getUniformLocation(prog, 'u_now'),
    p1: gl.getUniformLocation(prog, 'u_p1'),
    p2: gl.getUniformLocation(prog, 'u_p2'),
    p3: gl.getUniformLocation(prog, 'u_p3'),
    mask: gl.getUniformLocation(prog, 'u_mask'),
    freeze: gl.getUniformLocation(prog, 'u_freeze'),
    texel: gl.getUniformLocation(prog, 'u_texel'),
    mix: gl.getUniformLocation(prog, 'u_mix'),
    edge: gl.getUniformLocation(prog, 'u_edge'),
    warp: gl.getUniformLocation(prog, 'u_warp'),
    useFreeze: gl.getUniformLocation(prog, 'u_useFreeze')
  };

  function makeTex(unit, uniformLoc) {
    const tex = gl.createTexture();
    gl.activeTexture(gl.TEXTURE0 + unit);
    gl.bindTexture(gl.TEXTURE_2D, tex);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.uniform1i(uniformLoc, unit);
    return tex;
  }

  // texture units mapping
  const TEX = {
    now: makeTex(0, U.now),
    p1: makeTex(1, U.p1),
    p2: makeTex(2, U.p2),
    p3: makeTex(3, U.p3),
    mask: makeTex(4, U.mask),
    freeze: makeTex(5, U.freeze)
  };

  // ring buffer for past frames (store canvases)
  const RING = {
    size: 24,          // keep 24 frames history
    idx: 0,
    frames: []         // each is an Offscreen/Canvas
  };
  for (let i=0; i<RING.size; i++) {
    const c = document.createElement('canvas');
    c.width = 2; c.height = 2;
    RING.frames.push(c);
  }

  // work canvases
  const grab = document.createElement('canvas'); // current frame buffer
  const grabCtx = grab.getContext('2d', { willReadFrequently:false });

  const freezeCanvas = document.createElement('canvas');
  const freezeCtx = freezeCanvas.getContext('2d', { willReadFrequently:false });
  let useFreeze = 0;

  // ---------- Auto Freeze state ----------
  let autoMode = false;
  let autoFreezeReady = false;
  let clearFrameCount = 0;
  const CLEAR_FRAMES_NEEDED = 10; // Need 10 consecutive clear frames

  function checkIfFrameClear() {
    // Check if the segmentation mask shows no person (low mask values)
    if (!segReady) return false;
    
    const ctx = segmentationMaskCanvas.getContext('2d');
    const w = segmentationMaskCanvas.width;
    const h = segmentationMaskCanvas.height;
    
    // Sample some points to check mask coverage
    const sampleSize = 20;
    const imageData = ctx.getImageData(0, 0, w, h);
    const data = imageData.data;
    
    let personPixels = 0;
    let totalSamples = 0;
    
    for (let y = 0; y < h; y += Math.floor(h / sampleSize)) {
      for (let x = 0; x < w; x += Math.floor(w / sampleSize)) {
        const idx = (y * w + x) * 4;
        // Red channel contains mask value (higher = person)
        if (data[idx] > 128) personPixels++;
        totalSamples++;
      }
    }
    
    const personRatio = personPixels / totalSamples;
    return personRatio < 0.05; // Less than 5% person coverage = clear
  }

  function doAutoFreeze() {
    freezeCtx.drawImage(video, 0, 0, freezeCanvas.width, freezeCanvas.height);
    useFreeze = 1;
    autoFreezeReady = true;
    autoStatusEl.classList.add('ready');
    autoStatusText.textContent = 'Background captured! You can enter now.';
    
    // Auto enable gesture mode
    if (!gestureEnabled) {
      if (!hands) initHands();
      gestureEnabled = true;
      statusEl.style.display = 'block';
      btnGesture.textContent = '? Disable';
      updateCloakStatus();
    }
  }

  // ---------- Cloak state (gesture controlled) ----------
  let cloakEnabled = false;
  let gestureEnabled = false;
  let lastGestureTime = 0;
  const GESTURE_COOLDOWN = 1000; // 1 second cooldown to prevent flickering

  const statusEl = document.getElementById('status');
  const statusText = document.getElementById('statusText');
  const btnGesture = document.getElementById('btnGesture');

  function updateCloakStatus() {
    if (cloakEnabled) {
      statusEl.classList.add('active');
      statusText.textContent = 'CLOAK ON';
      mixEl.value = 1.0;
    } else {
      statusEl.classList.remove('active');
      statusText.textContent = 'CLOAK OFF';
      mixEl.value = 0;
    }
    syncUI();
  }

  // ---------- MediaPipe Hands (Gesture Detection) ----------
  let hands = null;
  let handResults = null;

  function isClosedFist(landmarks) {
    // Check if all fingers are closed (fist)
    // Compare fingertip positions with knuckle positions
    // Finger tips: 4(thumb), 8(index), 12(middle), 16(ring), 20(pinky)
    // Finger PIPs: 3(thumb), 6(index), 10(middle), 14(ring), 18(pinky)
    
    const tipIds = [8, 12, 16, 20]; // Index to pinky tips
    const pipIds = [6, 10, 14, 18]; // Index to pinky PIPs
    
    let closedFingers = 0;
    
    for (let i = 0; i < tipIds.length; i++) {
      const tip = landmarks[tipIds[i]];
      const pip = landmarks[pipIds[i]];
      // Finger is closed if tip is below (greater Y) than PIP
      if (tip.y > pip.y) {
        closedFingers++;
      }
    }
    
    // Check thumb separately (compare x position for right hand)
    const thumbTip = landmarks[4];
    const thumbIp = landmarks[3];
    const wrist = landmarks[0];
    
    // Determine if it's right or left hand based on thumb position relative to wrist
    const isRightHand = thumbTip.x < wrist.x;
    
    let thumbClosed = false;
    if (isRightHand) {
      thumbClosed = thumbTip.x > thumbIp.x;
    } else {
      thumbClosed = thumbTip.x < thumbIp.x;
    }
    
    // Fist = all 4 fingers closed + thumb closed
    return closedFingers >= 3 && thumbClosed;
  }

  function initHands() {
    hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });
    
    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 0, // 0 = lite, faster
      minDetectionConfidence: 0.6,
      minTrackingConfidence: 0.5
    });
    
    hands.onResults((results) => {
      handResults = results;
      
      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];
        const now = Date.now();
        
        if (isClosedFist(landmarks)) {
          // Toggle cloak with cooldown
          if (now - lastGestureTime > GESTURE_COOLDOWN) {
            cloakEnabled = !cloakEnabled;
            lastGestureTime = now;
            updateCloakStatus();
          }
        }
      }
    });
  }

  // ---------- MediaPipe Selfie Segmentation ----------
  let segmentationMaskCanvas = document.createElement('canvas'); // will be drawn by MediaPipe
  let segReady = false;

  const selfieSeg = new SelfieSegmentation({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`
  });
  selfieSeg.setOptions({
    modelSelection: 1, // 0: general, 1: landscape (better for environment)
  });
  selfieSeg.onResults((results) => {
    // results.segmentationMask is an HTMLCanvasElement-like
    // We copy it into our own canvas to use as a texture source.
    const m = results.segmentationMask;
    if (!m) return;

    if (segmentationMaskCanvas.width !== m.width || segmentationMaskCanvas.height !== m.height) {
      segmentationMaskCanvas.width = m.width;
      segmentationMaskCanvas.height = m.height;
    }
    const ctx = segmentationMaskCanvas.getContext('2d');
    ctx.clearRect(0,0,segmentationMaskCanvas.width, segmentationMaskCanvas.height);
    ctx.drawImage(m, 0, 0);
    segReady = true;
  });

  // ---------- camera & main loop ----------
  let running = false;

  async function start() {
    if (running) return;
    running = true;

    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: "user", width: { ideal: 1280 }, height: { ideal: 720 } },
      audio: false
    });
    video.srcObject = stream;
    await video.play();

    // resize canvases to video
    const w = video.videoWidth;
    const h = video.videoHeight;

    // output canvas size (keep original res for best mask edges)
    canvas.width = w;
    canvas.height = h;

    grab.width = w; grab.height = h;
    freezeCanvas.width = w; freezeCanvas.height = h;

    // init ring canvases sizes
    for (const c of RING.frames) { c.width = w; c.height = h; }

    gl.viewport(0, 0, w, h);
    gl.uniform2f(U.texel, 1 / w, 1 / h);

    btnFreeze.disabled = false;
    btnUnfreeze.disabled = false;
    btnGesture.disabled = false;

    // warm up: fill ring with current
    for (let i=0; i<RING.size; i++) {
      const c = RING.frames[i];
      const cctx = c.getContext('2d');
      cctx.drawImage(video, 0, 0, w, h);
    }

    requestAnimationFrame(loop);
  }

  function uploadToTex(tex, source) {
    gl.bindTexture(gl.TEXTURE_2D, tex);
    // Use texImage2D each time (simple). For perf, texSubImage2D also works.
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, source);
  }

  // pick past frames by delays (in frames)
  function getPastCanvas(delay) {
    let i = (RING.idx - delay) % RING.size;
    if (i < 0) i += RING.size;
    return RING.frames[i];
  }

  let frameCount = 0;
  async function loop() {
    if (!running) return;

    const w = canvas.width, h = canvas.height;

    // 1) grab current frame into grab canvas
    grabCtx.drawImage(video, 0, 0, w, h);

    // 2) push into ring buffer
    {
      const c = RING.frames[RING.idx];
      const cctx = c.getContext('2d');
      cctx.drawImage(grab, 0, 0);
      RING.idx = (RING.idx + 1) % RING.size;
    }

    // 3) run segmentation occasionally or every frame
    //   - every frame is best quality, but heavy on low-end devices.
    //   - if you want lighter, do: if (frameCount % 2 === 0) await...
    await selfieSeg.send({ image: grab });
    
    // 3.5) Auto freeze: check if frame is clear (no person)
    if (autoMode && !autoFreezeReady) {
      if (checkIfFrameClear()) {
        clearFrameCount++;
        autoStatusText.textContent = `Clear frame detected (${clearFrameCount}/${CLEAR_FRAMES_NEEDED})...`;
        
        if (clearFrameCount >= CLEAR_FRAMES_NEEDED) {
          doAutoFreeze();
        }
      } else {
        clearFrameCount = 0;
        autoStatusText.textContent = 'Step out of frame to capture background...';
      }
    }
    
    // 3.6) run hand detection if gesture is enabled
    if (gestureEnabled && hands && frameCount % 3 === 0) {
      await hands.send({ image: grab });
    }
    
    frameCount++;

    // 4) upload textures
    gl.activeTexture(gl.TEXTURE0);
    uploadToTex(TEX.now, grab);

    // delays: 6, 12, 18 frames (~200/400/600ms at 30fps)
    gl.activeTexture(gl.TEXTURE1);
    uploadToTex(TEX.p1, getPastCanvas(6));

    gl.activeTexture(gl.TEXTURE2);
    uploadToTex(TEX.p2, getPastCanvas(12));

    gl.activeTexture(gl.TEXTURE3);
    uploadToTex(TEX.p3, getPastCanvas(18));

    gl.activeTexture(gl.TEXTURE4);
    if (segReady) uploadToTex(TEX.mask, segmentationMaskCanvas);
    else uploadToTex(TEX.mask, grab); // fallback to prevent crash

    gl.activeTexture(gl.TEXTURE5);
    uploadToTex(TEX.freeze, freezeCanvas);

    // 5) uniforms from UI
    gl.uniform1f(U.mix, parseFloat(mixEl.value));
    gl.uniform1f(U.edge, parseFloat(edgeEl.value));
    gl.uniform1f(U.warp, parseFloat(warpEl.value));
    gl.uniform1f(U.useFreeze, useFreeze);

    // 6) draw
    gl.drawArrays(gl.TRIANGLES, 0, 6);

    requestAnimationFrame(loop);
  }

  btnStart.addEventListener('click', () => start().catch(err => {
    console.error(err);
    alert('Failed to start: ' + err.message);
  }));

  btnAutoStart.addEventListener('click', async () => {
    // Show countdown
    countdownEl.style.display = 'block';
    
    for (let i = 3; i >= 1; i--) {
      countdownEl.textContent = i;
      await new Promise(r => setTimeout(r, 1000));
    }
    countdownEl.textContent = 'GO!';
    await new Promise(r => setTimeout(r, 500));
    countdownEl.style.display = 'none';
    
    // Start camera
    await start();
    
    // Enable auto mode
    autoMode = true;
    autoFreezeReady = false;
    clearFrameCount = 0;
    autoStatusEl.style.display = 'block';
    autoStatusText.textContent = 'Step out of frame to capture background...';
  });

  btnFreeze.addEventListener('click', () => {
    if (!running) return;
    freezeCtx.drawImage(video, 0, 0, freezeCanvas.width, freezeCanvas.height);
    useFreeze = 1;
  });

  btnUnfreeze.addEventListener('click', () => {
    useFreeze = 0;
  });

  btnGesture.addEventListener('click', () => {
    if (!gestureEnabled) {
      if (!hands) initHands();
      gestureEnabled = true;
      statusEl.style.display = 'block';
      btnGesture.textContent = '? Disable';
      updateCloakStatus();
    } else {
      gestureEnabled = false;
      statusEl.style.display = 'none';
      btnGesture.textContent = '? Gesture';
      cloakEnabled = false;
      mixEl.value = 0.98;
      syncUI();
    }
  });

})();
</script>
</body>
</html>
